2025-09-20 19:24:24,862 [trainer.py] => dataset: cifar100_224
2025-09-20 19:24:24,862 [trainer.py] => smart_defaults: True
2025-09-20 19:24:24,862 [trainer.py] => user: authors
2025-09-20 19:24:24,862 [trainer.py] => test: True
2025-09-20 19:24:24,862 [trainer.py] => memory_size: 0
2025-09-20 19:24:24,862 [trainer.py] => memory_per_class: 0
2025-09-20 19:24:24,862 [trainer.py] => fixed_memory: False
2025-09-20 19:24:24,862 [trainer.py] => shuffle: True
2025-09-20 19:24:24,862 [trainer.py] => init_cls: 10
2025-09-20 19:24:24,862 [trainer.py] => increment: 10
2025-09-20 19:24:24,862 [trainer.py] => model_name: sldc
2025-09-20 19:24:24,862 [trainer.py] => vit_type: vit-b-p16
2025-09-20 19:24:24,862 [trainer.py] => weight_decay: 0.0
2025-09-20 19:24:24,862 [trainer.py] => device: [device(type='cuda', index=0)]
2025-09-20 19:24:24,862 [trainer.py] => lora_rank: 4
2025-09-20 19:24:24,862 [trainer.py] => lora_type: sgp_lora
2025-09-20 19:24:24,862 [trainer.py] => weight_temp: 5.0
2025-09-20 19:24:24,862 [trainer.py] => weight_kind: log1p
2025-09-20 19:24:24,862 [trainer.py] => weight_p: 1.0
2025-09-20 19:24:24,862 [trainer.py] => nsp_eps: 0.05
2025-09-20 19:24:24,862 [trainer.py] => nsp_weight: 0.0
2025-09-20 19:24:24,862 [trainer.py] => sce_a: 0.5
2025-09-20 19:24:24,862 [trainer.py] => sce_b: 0.5
2025-09-20 19:24:24,862 [trainer.py] => seed_list: [1993]
2025-09-20 19:24:24,863 [trainer.py] => iterations: 2500
2025-09-20 19:24:24,863 [trainer.py] => warmup_steps: 200
2025-09-20 19:24:24,863 [trainer.py] => ca_epochs: 5
2025-09-20 19:24:24,863 [trainer.py] => optimizer: sgd
2025-09-20 19:24:24,863 [trainer.py] => lrate: 0.002
2025-09-20 19:24:24,863 [trainer.py] => batch_size: 24
2025-09-20 19:24:24,863 [trainer.py] => gamma_norm: 0.1
2025-09-20 19:24:24,863 [trainer.py] => gamma_kd: 0.0
2025-09-20 19:24:24,863 [trainer.py] => kd_type: feat
2025-09-20 19:24:24,863 [trainer.py] => compensate: True
2025-09-20 19:24:24,863 [trainer.py] => eval_only: False
2025-09-20 19:24:24,863 [trainer.py] => auxiliary_data_path: /data1/open_datasets/ImageNet-2012/train
2025-09-20 19:24:24,863 [trainer.py] => aux_dataset: imagenet
2025-09-20 19:24:24,863 [trainer.py] => auxiliary_data_size: 1024
2025-09-20 19:24:24,863 [trainer.py] => l2_protection: True
2025-09-20 19:24:24,863 [trainer.py] => l2_protection_lambda: 0.0001
2025-09-20 19:24:24,863 [trainer.py] => seed: 1993
2025-09-20 19:24:24,863 [trainer.py] => run_id: 0
2025-09-20 19:24:24,863 [trainer.py] => log_path: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993
2025-09-20 19:24:24,863 [data_manager.py] => [DataManager] args_for_idata = {'dataset': 'cifar100_224', 'smart_defaults': True, 'user': 'authors', 'test': True, 'memory_size': 0, 'memory_per_class': 0, 'fixed_memory': False, 'shuffle': True, 'init_cls': 10, 'increment': 10, 'model_name': 'sldc', 'vit_type': 'vit-b-p16', 'weight_decay': 0.0, 'device': [device(type='cuda', index=0)], 'lora_rank': 4, 'lora_type': 'sgp_lora', 'weight_temp': 5.0, 'weight_kind': 'log1p', 'weight_p': 1.0, 'nsp_eps': 0.05, 'nsp_weight': 0.0, 'sce_a': 0.5, 'sce_b': 0.5, 'seed_list': [1993], 'iterations': 2500, 'warmup_steps': 200, 'ca_epochs': 5, 'optimizer': 'sgd', 'lrate': 0.002, 'batch_size': 24, 'gamma_norm': 0.1, 'gamma_kd': 0.0, 'kd_type': 'feat', 'compensate': True, 'eval_only': False, 'auxiliary_data_path': '/data1/open_datasets/ImageNet-2012/train', 'aux_dataset': 'imagenet', 'auxiliary_data_size': 1024, 'l2_protection': True, 'l2_protection_lambda': 0.0001, 'seed': 1993, 'run_id': 0, 'log_path': 'sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993'}
2025-09-20 19:24:26,811 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-09-20 19:24:28,098 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-09-20 19:24:28,870 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-09-20 19:24:45,653 [subspace_lora.py] => Compiled network with torch.compile
2025-09-20 19:24:45,653 [subspace_lora.py] => Optimizer instantiated: lrate=0.002, wd=0.0, optimizer=sgd
2025-09-20 19:24:45,654 [trainer.py] => All params: 86469888
2025-09-20 19:24:45,655 [trainer.py] => Trainable params: 672768
2025-09-20 19:24:45,778 [subspace_lora.py] => System training on classes 0-10 (cifar100_224)
2025-09-20 19:25:05,909 [subspace_lora.py] => step: 200, loss: -0.3053, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.9142
2025-09-20 19:25:20,864 [trainer.py] => dataset: cifar100_224
2025-09-20 19:25:20,864 [trainer.py] => smart_defaults: True
2025-09-20 19:25:20,864 [trainer.py] => user: authors
2025-09-20 19:25:20,864 [trainer.py] => test: True
2025-09-20 19:25:20,864 [trainer.py] => memory_size: 0
2025-09-20 19:25:20,864 [trainer.py] => memory_per_class: 0
2025-09-20 19:25:20,864 [trainer.py] => fixed_memory: False
2025-09-20 19:25:20,864 [trainer.py] => shuffle: True
2025-09-20 19:25:20,864 [trainer.py] => init_cls: 10
2025-09-20 19:25:20,864 [trainer.py] => increment: 10
2025-09-20 19:25:20,864 [trainer.py] => model_name: sldc
2025-09-20 19:25:20,864 [trainer.py] => vit_type: vit-b-p16
2025-09-20 19:25:20,865 [trainer.py] => weight_decay: 0.0
2025-09-20 19:25:20,865 [trainer.py] => device: [device(type='cuda', index=0)]
2025-09-20 19:25:20,865 [trainer.py] => lora_rank: 4
2025-09-20 19:25:20,865 [trainer.py] => lora_type: sgp_lora
2025-09-20 19:25:20,865 [trainer.py] => weight_temp: 5.0
2025-09-20 19:25:20,865 [trainer.py] => weight_kind: log1p
2025-09-20 19:25:20,865 [trainer.py] => weight_p: 1.0
2025-09-20 19:25:20,865 [trainer.py] => nsp_eps: 0.05
2025-09-20 19:25:20,865 [trainer.py] => nsp_weight: 0.0
2025-09-20 19:25:20,865 [trainer.py] => sce_a: 0.5
2025-09-20 19:25:20,865 [trainer.py] => sce_b: 0.5
2025-09-20 19:25:20,865 [trainer.py] => seed_list: [1993]
2025-09-20 19:25:20,865 [trainer.py] => iterations: 2500
2025-09-20 19:25:20,865 [trainer.py] => warmup_steps: 200
2025-09-20 19:25:20,865 [trainer.py] => ca_epochs: 5
2025-09-20 19:25:20,865 [trainer.py] => optimizer: sgd
2025-09-20 19:25:20,865 [trainer.py] => lrate: 0.002
2025-09-20 19:25:20,865 [trainer.py] => batch_size: 24
2025-09-20 19:25:20,865 [trainer.py] => gamma_norm: 0.1
2025-09-20 19:25:20,865 [trainer.py] => gamma_kd: 0.0
2025-09-20 19:25:20,865 [trainer.py] => kd_type: feat
2025-09-20 19:25:20,865 [trainer.py] => compensate: True
2025-09-20 19:25:20,865 [trainer.py] => eval_only: False
2025-09-20 19:25:20,865 [trainer.py] => auxiliary_data_path: /data1/open_datasets/ImageNet-2012/train
2025-09-20 19:25:20,865 [trainer.py] => aux_dataset: imagenet
2025-09-20 19:25:20,865 [trainer.py] => auxiliary_data_size: 1024
2025-09-20 19:25:20,865 [trainer.py] => l2_protection: True
2025-09-20 19:25:20,865 [trainer.py] => l2_protection_lambda: 0.0001
2025-09-20 19:25:20,865 [trainer.py] => seed: 1993
2025-09-20 19:25:20,865 [trainer.py] => run_id: 0
2025-09-20 19:25:20,865 [trainer.py] => log_path: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993
2025-09-20 19:25:20,866 [data_manager.py] => [DataManager] args_for_idata = {'dataset': 'cifar100_224', 'smart_defaults': True, 'user': 'authors', 'test': True, 'memory_size': 0, 'memory_per_class': 0, 'fixed_memory': False, 'shuffle': True, 'init_cls': 10, 'increment': 10, 'model_name': 'sldc', 'vit_type': 'vit-b-p16', 'weight_decay': 0.0, 'device': [device(type='cuda', index=0)], 'lora_rank': 4, 'lora_type': 'sgp_lora', 'weight_temp': 5.0, 'weight_kind': 'log1p', 'weight_p': 1.0, 'nsp_eps': 0.05, 'nsp_weight': 0.0, 'sce_a': 0.5, 'sce_b': 0.5, 'seed_list': [1993], 'iterations': 2500, 'warmup_steps': 200, 'ca_epochs': 5, 'optimizer': 'sgd', 'lrate': 0.002, 'batch_size': 24, 'gamma_norm': 0.1, 'gamma_kd': 0.0, 'kd_type': 'feat', 'compensate': True, 'eval_only': False, 'auxiliary_data_path': '/data1/open_datasets/ImageNet-2012/train', 'aux_dataset': 'imagenet', 'auxiliary_data_size': 1024, 'l2_protection': True, 'l2_protection_lambda': 0.0001, 'seed': 1993, 'run_id': 0, 'log_path': 'sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993'}
2025-09-20 19:25:22,825 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-09-20 19:25:24,198 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-09-20 19:25:24,775 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-09-20 19:25:41,791 [subspace_lora.py] => Compiled network with torch.compile
2025-09-20 19:25:41,791 [subspace_lora.py] => Optimizer instantiated: lrate=0.002, wd=0.0, optimizer=sgd
2025-09-20 19:25:41,792 [trainer.py] => All params: 86469888
2025-09-20 19:25:41,792 [trainer.py] => Trainable params: 672768
2025-09-20 19:25:41,900 [subspace_lora.py] => System training on classes 0-10 (cifar100_224)
2025-09-20 19:26:01,869 [subspace_lora.py] => step: 200, loss: -0.2945, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.9129
2025-09-20 19:26:21,401 [subspace_lora.py] => step: 400, loss: -0.3487, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.9303
2025-09-20 19:26:40,996 [subspace_lora.py] => step: 600, loss: -0.3238, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.9180
2025-09-20 19:27:00,671 [subspace_lora.py] => step: 800, loss: -0.3733, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.9458
2025-09-20 19:27:20,337 [subspace_lora.py] => step: 1000, loss: -0.3629, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.9401
2025-09-20 19:27:40,011 [subspace_lora.py] => step: 1200, loss: -0.3773, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.9533
2025-09-20 19:27:59,699 [subspace_lora.py] => step: 1400, loss: -0.4266, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.9659
2025-09-20 19:28:19,366 [subspace_lora.py] => step: 1600, loss: -0.4265, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.9693
2025-09-20 19:28:39,048 [subspace_lora.py] => step: 1800, loss: -0.3709, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.9503
2025-09-20 19:28:58,676 [subspace_lora.py] => step: 2000, loss: -0.3756, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.9474
2025-09-20 19:29:18,234 [subspace_lora.py] => step: 2200, loss: -0.3976, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.9664
2025-09-20 19:29:37,801 [subspace_lora.py] => step: 2400, loss: -0.3727, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.9458
2025-09-20 19:29:47,438 [subspace_lora.py] => Checkpoint saved to: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993/after_task_1.pth
2025-09-20 19:30:03,282 [subspace_lora.py] => Task 1 finished – total: 261.49 s | train: 245.52 s | drift: 15.84 s
2025-09-20 19:30:09,397 [subspace_lora.py] => Evaluating after task 1...
2025-09-20 19:30:11,130 [subspace_lora.py] => 📊 Incremental Learning Evaluation Analysis:
2025-09-20 19:30:11,130 [subspace_lora.py] =>    Last Task ID: 1
2025-09-20 19:30:11,130 [subspace_lora.py] =>   ── Final Task Accuracy (%) ──
2025-09-20 19:30:11,130 [subspace_lora.py] =>       per-class            : 99.10%
2025-09-20 19:30:11,130 [subspace_lora.py] =>       per-class_compensate : 99.10%
2025-09-20 19:30:11,130 [subspace_lora.py] =>    ── Average Accuracy Across Tasks (%) ──
2025-09-20 19:30:11,130 [subspace_lora.py] =>       per-class            : 99.10%
2025-09-20 19:30:11,130 [subspace_lora.py] =>       per-class_compensate : 99.10%
2025-09-20 19:30:11,130 [subspace_lora.py] =>    ── Summary ──
2025-09-20 19:30:11,130 [subspace_lora.py] =>       🏆 Variant 'per-class' is best in both final task and average performance.
2025-09-20 19:30:24,920 [subspace_lora.py] => System training on classes 10-20 (cifar100_224)
2025-09-20 19:30:44,035 [subspace_lora.py] => step: 200, loss: -0.2905, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7563
2025-09-20 19:31:02,803 [subspace_lora.py] => step: 400, loss: -0.3206, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8004
2025-09-20 19:31:21,689 [subspace_lora.py] => step: 600, loss: -0.3298, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8126
2025-09-20 19:31:40,603 [subspace_lora.py] => step: 800, loss: -0.3321, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8400
2025-09-20 19:31:59,521 [subspace_lora.py] => step: 1000, loss: -0.3448, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8709
2025-09-20 19:32:18,402 [subspace_lora.py] => step: 1200, loss: -0.3225, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8306
2025-09-20 19:32:37,257 [subspace_lora.py] => step: 1400, loss: -0.3568, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8724
2025-09-20 19:32:56,117 [subspace_lora.py] => step: 1600, loss: -0.3231, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8488
2025-09-20 19:33:14,993 [subspace_lora.py] => step: 1800, loss: -0.3631, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8567
2025-09-20 19:33:33,887 [subspace_lora.py] => step: 2000, loss: -0.3384, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8588
2025-09-20 19:33:52,801 [subspace_lora.py] => step: 2200, loss: -0.3901, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8647
2025-09-20 19:34:11,701 [subspace_lora.py] => step: 2400, loss: -0.3866, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8635
2025-09-20 19:34:21,013 [subspace_lora.py] => Checkpoint saved to: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993/after_task_2.pth
2025-09-20 19:34:41,897 [subspace_lora.py] => Task 2 finished – total: 257.36 s | train: 236.07 s | drift: 20.88 s
2025-09-20 19:34:48,987 [subspace_lora.py] => Evaluating after task 2...
2025-09-20 19:34:52,219 [subspace_lora.py] => 📊 Incremental Learning Evaluation Analysis:
2025-09-20 19:34:52,219 [subspace_lora.py] =>    Last Task ID: 2
2025-09-20 19:34:52,219 [subspace_lora.py] =>   ── Final Task Accuracy (%) ──
2025-09-20 19:34:52,219 [subspace_lora.py] =>       per-class            : 97.50%
2025-09-20 19:34:52,219 [subspace_lora.py] =>       per-class_compensate : 97.45%
2025-09-20 19:34:52,220 [subspace_lora.py] =>    ── Average Accuracy Across Tasks (%) ──
2025-09-20 19:34:52,220 [subspace_lora.py] =>       per-class            : 98.30%
2025-09-20 19:34:52,220 [subspace_lora.py] =>       per-class_compensate : 98.28%
2025-09-20 19:34:52,220 [subspace_lora.py] =>    ── Summary ──
2025-09-20 19:34:52,220 [subspace_lora.py] =>       🏆 Variant 'per-class' is best in both final task and average performance.
2025-09-20 19:35:05,958 [subspace_lora.py] => System training on classes 20-30 (cifar100_224)
2025-09-20 19:35:25,297 [subspace_lora.py] => step: 200, loss: -0.3789, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6912
2025-09-20 19:35:44,374 [subspace_lora.py] => step: 400, loss: -0.4118, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7910
2025-09-20 19:36:03,255 [subspace_lora.py] => step: 600, loss: -0.3873, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7726
2025-09-20 19:36:22,247 [subspace_lora.py] => step: 800, loss: -0.3869, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8045
2025-09-20 19:36:41,342 [subspace_lora.py] => step: 1000, loss: -0.4297, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8367
2025-09-20 19:37:00,416 [subspace_lora.py] => step: 1200, loss: -0.4317, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8492
2025-09-20 19:37:19,477 [subspace_lora.py] => step: 1400, loss: -0.4021, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7913
2025-09-20 19:37:38,476 [subspace_lora.py] => step: 1600, loss: -0.4038, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8619
2025-09-20 19:37:57,413 [subspace_lora.py] => step: 1800, loss: -0.4373, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8874
2025-09-20 19:38:16,392 [subspace_lora.py] => step: 2000, loss: -0.4340, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.9043
2025-09-20 19:38:35,342 [subspace_lora.py] => step: 2200, loss: -0.4423, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8765
2025-09-20 19:38:54,292 [subspace_lora.py] => step: 2400, loss: -0.3934, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8717
2025-09-20 19:39:03,464 [subspace_lora.py] => Checkpoint saved to: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993/after_task_3.pth
2025-09-20 19:39:22,814 [subspace_lora.py] => Task 3 finished – total: 257.30 s | train: 237.49 s | drift: 19.35 s
2025-09-20 19:39:29,654 [subspace_lora.py] => Evaluating after task 3...
2025-09-20 19:39:34,235 [subspace_lora.py] => 📊 Incremental Learning Evaluation Analysis:
2025-09-20 19:39:34,235 [subspace_lora.py] =>    Last Task ID: 3
2025-09-20 19:39:34,235 [subspace_lora.py] =>   ── Final Task Accuracy (%) ──
2025-09-20 19:39:34,235 [subspace_lora.py] =>       per-class            : 96.10%
2025-09-20 19:39:34,235 [subspace_lora.py] =>       per-class_compensate : 96.00%
2025-09-20 19:39:34,235 [subspace_lora.py] =>    ── Average Accuracy Across Tasks (%) ──
2025-09-20 19:39:34,235 [subspace_lora.py] =>       per-class            : 97.57%
2025-09-20 19:39:34,235 [subspace_lora.py] =>       per-class_compensate : 97.52%
2025-09-20 19:39:34,235 [subspace_lora.py] =>    ── Summary ──
2025-09-20 19:39:34,235 [subspace_lora.py] =>       🏆 Variant 'per-class' is best in both final task and average performance.
2025-09-20 19:39:48,092 [subspace_lora.py] => System training on classes 30-40 (cifar100_224)
2025-09-20 19:40:06,542 [subspace_lora.py] => step: 200, loss: -0.3434, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6085
2025-09-20 19:40:24,733 [subspace_lora.py] => step: 400, loss: -0.3513, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6682
2025-09-20 19:40:42,987 [subspace_lora.py] => step: 600, loss: -0.3453, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6944
2025-09-20 19:41:01,186 [subspace_lora.py] => step: 800, loss: -0.3644, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7024
2025-09-20 19:41:19,379 [subspace_lora.py] => step: 1000, loss: -0.3164, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7304
2025-09-20 19:41:37,578 [subspace_lora.py] => step: 1200, loss: -0.4083, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7732
2025-09-20 19:41:55,837 [subspace_lora.py] => step: 1400, loss: -0.3317, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7780
2025-09-20 19:42:14,023 [subspace_lora.py] => step: 1600, loss: -0.3770, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7856
2025-09-20 19:42:32,357 [subspace_lora.py] => step: 1800, loss: -0.3907, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7883
2025-09-20 19:42:50,825 [subspace_lora.py] => step: 2000, loss: -0.3965, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7977
2025-09-20 19:43:09,294 [subspace_lora.py] => step: 2200, loss: -0.3961, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.8059
2025-09-20 19:43:27,767 [subspace_lora.py] => step: 2400, loss: -0.4130, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7942
2025-09-20 19:43:36,827 [subspace_lora.py] => Checkpoint saved to: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993/after_task_4.pth
2025-09-20 19:43:56,992 [subspace_lora.py] => Task 4 finished – total: 249.39 s | train: 228.72 s | drift: 20.16 s
2025-09-20 19:44:04,479 [subspace_lora.py] => Evaluating after task 4...
2025-09-20 19:44:10,697 [subspace_lora.py] => 📊 Incremental Learning Evaluation Analysis:
2025-09-20 19:44:10,698 [subspace_lora.py] =>    Last Task ID: 4
2025-09-20 19:44:10,698 [subspace_lora.py] =>   ── Final Task Accuracy (%) ──
2025-09-20 19:44:10,698 [subspace_lora.py] =>       per-class            : 95.70%
2025-09-20 19:44:10,698 [subspace_lora.py] =>       per-class_compensate : 95.55%
2025-09-20 19:44:10,698 [subspace_lora.py] =>    ── Average Accuracy Across Tasks (%) ──
2025-09-20 19:44:10,698 [subspace_lora.py] =>       per-class            : 97.10%
2025-09-20 19:44:10,698 [subspace_lora.py] =>       per-class_compensate : 97.03%
2025-09-20 19:44:10,698 [subspace_lora.py] =>    ── Summary ──
2025-09-20 19:44:10,698 [subspace_lora.py] =>       🏆 Variant 'per-class' is best in both final task and average performance.
2025-09-20 19:44:24,549 [subspace_lora.py] => System training on classes 40-50 (cifar100_224)
2025-09-20 19:44:43,829 [subspace_lora.py] => step: 200, loss: -0.3573, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.4727
2025-09-20 19:45:02,957 [subspace_lora.py] => step: 400, loss: -0.3759, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5799
2025-09-20 19:45:22,093 [subspace_lora.py] => step: 600, loss: -0.4173, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6333
2025-09-20 19:45:41,267 [subspace_lora.py] => step: 800, loss: -0.4069, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6618
2025-09-20 19:46:00,441 [subspace_lora.py] => step: 1000, loss: -0.4176, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6620
2025-09-20 19:46:19,610 [subspace_lora.py] => step: 1200, loss: -0.3864, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6336
2025-09-20 19:46:38,787 [subspace_lora.py] => step: 1400, loss: -0.4105, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6837
2025-09-20 19:46:57,936 [subspace_lora.py] => step: 1600, loss: -0.4194, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6801
2025-09-20 19:47:17,093 [subspace_lora.py] => step: 1800, loss: -0.4221, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6896
2025-09-20 19:47:36,248 [subspace_lora.py] => step: 2000, loss: -0.4156, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7244
2025-09-20 19:47:55,406 [subspace_lora.py] => step: 2200, loss: -0.4346, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7692
2025-09-20 19:48:14,526 [subspace_lora.py] => step: 2400, loss: -0.4022, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7613
2025-09-20 19:48:23,948 [subspace_lora.py] => Checkpoint saved to: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993/after_task_5.pth
2025-09-20 19:48:45,658 [subspace_lora.py] => Task 5 finished – total: 261.60 s | train: 239.38 s | drift: 21.71 s
2025-09-20 19:48:51,891 [subspace_lora.py] => Evaluating after task 5...
2025-09-20 19:48:59,455 [subspace_lora.py] => 📊 Incremental Learning Evaluation Analysis:
2025-09-20 19:48:59,455 [subspace_lora.py] =>    Last Task ID: 5
2025-09-20 19:48:59,455 [subspace_lora.py] =>   ── Final Task Accuracy (%) ──
2025-09-20 19:48:59,455 [subspace_lora.py] =>       per-class            : 94.46%
2025-09-20 19:48:59,455 [subspace_lora.py] =>       per-class_compensate : 94.56%
2025-09-20 19:48:59,455 [subspace_lora.py] =>    ── Average Accuracy Across Tasks (%) ──
2025-09-20 19:48:59,455 [subspace_lora.py] =>       per-class            : 96.57%
2025-09-20 19:48:59,455 [subspace_lora.py] =>       per-class_compensate : 96.53%
2025-09-20 19:48:59,455 [subspace_lora.py] =>    ── Summary ──
2025-09-20 19:48:59,455 [subspace_lora.py] =>       🥇 Best in Final Task: 'per-class_compensate' | 📈 Best Average: 'per-class'
2025-09-20 19:49:13,321 [subspace_lora.py] => System training on classes 50-60 (cifar100_224)
2025-09-20 19:49:31,907 [subspace_lora.py] => step: 200, loss: -0.3397, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.4906
2025-09-20 19:49:50,108 [subspace_lora.py] => step: 400, loss: -0.3363, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5565
2025-09-20 19:50:08,373 [subspace_lora.py] => step: 600, loss: -0.3283, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6475
2025-09-20 19:50:26,497 [subspace_lora.py] => step: 800, loss: -0.3666, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6482
2025-09-20 19:50:44,656 [subspace_lora.py] => step: 1000, loss: -0.3811, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6983
2025-09-20 19:51:02,839 [subspace_lora.py] => step: 1200, loss: -0.4060, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7279
2025-09-20 19:51:21,147 [subspace_lora.py] => step: 1400, loss: -0.3911, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7521
2025-09-20 19:51:39,313 [subspace_lora.py] => step: 1600, loss: -0.3985, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7304
2025-09-20 19:51:57,493 [subspace_lora.py] => step: 1800, loss: -0.3732, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6995
2025-09-20 19:52:15,704 [subspace_lora.py] => step: 2000, loss: -0.3962, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7241
2025-09-20 19:52:33,866 [subspace_lora.py] => step: 2200, loss: -0.3729, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7718
2025-09-20 19:52:51,987 [subspace_lora.py] => step: 2400, loss: -0.4083, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7448
2025-09-20 19:53:00,911 [subspace_lora.py] => Checkpoint saved to: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993/after_task_6.pth
2025-09-20 19:53:23,248 [subspace_lora.py] => Task 6 finished – total: 250.55 s | train: 227.57 s | drift: 22.34 s
2025-09-20 19:53:31,444 [subspace_lora.py] => Evaluating after task 6...
2025-09-20 19:53:40,400 [subspace_lora.py] => 📊 Incremental Learning Evaluation Analysis:
2025-09-20 19:53:40,400 [subspace_lora.py] =>    Last Task ID: 6
2025-09-20 19:53:40,400 [subspace_lora.py] =>   ── Final Task Accuracy (%) ──
2025-09-20 19:53:40,400 [subspace_lora.py] =>       per-class            : 93.33%
2025-09-20 19:53:40,400 [subspace_lora.py] =>       per-class_compensate : 93.67%
2025-09-20 19:53:40,400 [subspace_lora.py] =>    ── Average Accuracy Across Tasks (%) ──
2025-09-20 19:53:40,400 [subspace_lora.py] =>       per-class            : 96.03%
2025-09-20 19:53:40,400 [subspace_lora.py] =>       per-class_compensate : 96.06%
2025-09-20 19:53:40,400 [subspace_lora.py] =>    ── Summary ──
2025-09-20 19:53:40,400 [subspace_lora.py] =>       🏆 Variant 'per-class_compensate' is best in both final task and average performance.
2025-09-20 19:53:54,296 [subspace_lora.py] => System training on classes 60-70 (cifar100_224)
2025-09-20 19:54:12,810 [subspace_lora.py] => step: 200, loss: -0.3942, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5886
2025-09-20 19:54:30,979 [subspace_lora.py] => step: 400, loss: -0.3804, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6303
2025-09-20 19:54:49,121 [subspace_lora.py] => step: 600, loss: -0.4046, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6977
2025-09-20 19:55:07,318 [subspace_lora.py] => step: 800, loss: -0.4236, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6989
2025-09-20 19:55:25,792 [subspace_lora.py] => step: 1000, loss: -0.4319, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7667
2025-09-20 19:55:44,942 [subspace_lora.py] => step: 1200, loss: -0.4299, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7521
2025-09-20 19:56:04,088 [subspace_lora.py] => step: 1400, loss: -0.4074, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7393
2025-09-20 19:56:23,248 [subspace_lora.py] => step: 1600, loss: -0.4252, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7552
2025-09-20 19:56:42,394 [subspace_lora.py] => step: 1800, loss: -0.4557, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7339
2025-09-20 19:57:01,567 [subspace_lora.py] => step: 2000, loss: -0.4319, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7495
2025-09-20 19:57:20,758 [subspace_lora.py] => step: 2200, loss: -0.4405, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7744
2025-09-20 19:57:39,889 [subspace_lora.py] => step: 2400, loss: -0.4360, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.7470
2025-09-20 19:57:49,328 [subspace_lora.py] => Checkpoint saved to: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993/after_task_7.pth
2025-09-20 19:58:12,530 [subspace_lora.py] => Task 7 finished – total: 258.79 s | train: 235.01 s | drift: 23.20 s
2025-09-20 19:58:20,723 [subspace_lora.py] => Evaluating after task 7...
2025-09-20 19:58:31,187 [subspace_lora.py] => 📊 Incremental Learning Evaluation Analysis:
2025-09-20 19:58:31,187 [subspace_lora.py] =>    Last Task ID: 7
2025-09-20 19:58:31,188 [subspace_lora.py] =>   ── Final Task Accuracy (%) ──
2025-09-20 19:58:31,188 [subspace_lora.py] =>       per-class            : 93.00%
2025-09-20 19:58:31,188 [subspace_lora.py] =>       per-class_compensate : 93.06%
2025-09-20 19:58:31,188 [subspace_lora.py] =>    ── Average Accuracy Across Tasks (%) ──
2025-09-20 19:58:31,188 [subspace_lora.py] =>       per-class            : 95.60%
2025-09-20 19:58:31,188 [subspace_lora.py] =>       per-class_compensate : 95.63%
2025-09-20 19:58:31,188 [subspace_lora.py] =>    ── Summary ──
2025-09-20 19:58:31,188 [subspace_lora.py] =>       🏆 Variant 'per-class_compensate' is best in both final task and average performance.
2025-09-20 19:58:45,062 [subspace_lora.py] => System training on classes 70-80 (cifar100_224)
2025-09-20 19:59:04,628 [subspace_lora.py] => step: 200, loss: -0.3017, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.2639
2025-09-20 19:59:23,877 [subspace_lora.py] => step: 400, loss: -0.3642, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.3684
2025-09-20 19:59:43,034 [subspace_lora.py] => step: 600, loss: -0.3466, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.4698
2025-09-20 20:00:02,274 [subspace_lora.py] => step: 800, loss: -0.3825, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.4903
2025-09-20 20:00:21,541 [subspace_lora.py] => step: 1000, loss: -0.3576, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.4514
2025-09-20 20:00:40,836 [subspace_lora.py] => step: 1200, loss: -0.3830, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.4494
2025-09-20 20:01:00,098 [subspace_lora.py] => step: 1400, loss: -0.3976, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5133
2025-09-20 20:01:19,365 [subspace_lora.py] => step: 1600, loss: -0.3817, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5132
2025-09-20 20:01:38,633 [subspace_lora.py] => step: 1800, loss: -0.3962, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5246
2025-09-20 20:01:57,932 [subspace_lora.py] => step: 2000, loss: -0.3591, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.4928
2025-09-20 20:02:17,219 [subspace_lora.py] => step: 2200, loss: -0.3785, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5199
2025-09-20 20:02:36,498 [subspace_lora.py] => step: 2400, loss: -0.3727, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.4986
2025-09-20 20:02:45,997 [subspace_lora.py] => Checkpoint saved to: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993/after_task_8.pth
2025-09-20 20:03:10,294 [subspace_lora.py] => Task 8 finished – total: 265.87 s | train: 240.91 s | drift: 24.30 s
2025-09-20 20:03:19,758 [subspace_lora.py] => Evaluating after task 8...
2025-09-20 20:03:31,578 [subspace_lora.py] => 📊 Incremental Learning Evaluation Analysis:
2025-09-20 20:03:31,578 [subspace_lora.py] =>    Last Task ID: 8
2025-09-20 20:03:31,579 [subspace_lora.py] =>   ── Final Task Accuracy (%) ──
2025-09-20 20:03:31,579 [subspace_lora.py] =>       per-class            : 91.00%
2025-09-20 20:03:31,579 [subspace_lora.py] =>       per-class_compensate : 91.62%
2025-09-20 20:03:31,579 [subspace_lora.py] =>    ── Average Accuracy Across Tasks (%) ──
2025-09-20 20:03:31,579 [subspace_lora.py] =>       per-class            : 95.02%
2025-09-20 20:03:31,579 [subspace_lora.py] =>       per-class_compensate : 95.13%
2025-09-20 20:03:31,579 [subspace_lora.py] =>    ── Summary ──
2025-09-20 20:03:31,579 [subspace_lora.py] =>       🏆 Variant 'per-class_compensate' is best in both final task and average performance.
2025-09-20 20:03:45,630 [subspace_lora.py] => System training on classes 80-90 (cifar100_224)
2025-09-20 20:04:04,698 [subspace_lora.py] => step: 200, loss: -0.3389, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.3438
2025-09-20 20:04:23,488 [subspace_lora.py] => step: 400, loss: -0.3637, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.4189
2025-09-20 20:04:42,381 [subspace_lora.py] => step: 600, loss: -0.3635, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5127
2025-09-20 20:05:00,761 [subspace_lora.py] => step: 800, loss: -0.3833, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5192
2025-09-20 20:05:18,975 [subspace_lora.py] => step: 1000, loss: -0.4058, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5403
2025-09-20 20:05:37,185 [subspace_lora.py] => step: 1200, loss: -0.4108, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5124
2025-09-20 20:05:55,478 [subspace_lora.py] => step: 1400, loss: -0.3849, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5577
2025-09-20 20:06:14,024 [subspace_lora.py] => step: 1600, loss: -0.4208, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5943
2025-09-20 20:06:32,903 [subspace_lora.py] => step: 1800, loss: -0.3714, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6015
2025-09-20 20:06:51,341 [subspace_lora.py] => step: 2000, loss: -0.4102, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5777
2025-09-20 20:07:09,664 [subspace_lora.py] => step: 2200, loss: -0.3908, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.5717
2025-09-20 20:07:27,814 [subspace_lora.py] => step: 2400, loss: -0.3740, kd_loss: 0.0000, prior_loss: 0.0000, acc: 0.6083
2025-09-20 20:07:36,777 [subspace_lora.py] => Checkpoint saved to: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993/after_task_9.pth
2025-09-20 20:08:02,576 [subspace_lora.py] => Task 9 finished – total: 257.59 s | train: 231.13 s | drift: 25.80 s
2025-09-20 20:08:12,523 [subspace_lora.py] => Evaluating after task 9...
2025-09-20 20:08:25,943 [subspace_lora.py] => 📊 Incremental Learning Evaluation Analysis:
2025-09-20 20:08:25,943 [subspace_lora.py] =>    Last Task ID: 9
2025-09-20 20:08:25,943 [subspace_lora.py] =>   ── Final Task Accuracy (%) ──
2025-09-20 20:08:25,943 [subspace_lora.py] =>       per-class            : 90.39%
2025-09-20 20:08:25,943 [subspace_lora.py] =>       per-class_compensate : 91.10%
2025-09-20 20:08:25,943 [subspace_lora.py] =>    ── Average Accuracy Across Tasks (%) ──
2025-09-20 20:08:25,943 [subspace_lora.py] =>       per-class            : 94.51%
2025-09-20 20:08:25,943 [subspace_lora.py] =>       per-class_compensate : 94.68%
2025-09-20 20:08:25,943 [subspace_lora.py] =>    ── Summary ──
2025-09-20 20:08:25,943 [subspace_lora.py] =>       🏆 Variant 'per-class_compensate' is best in both final task and average performance.
2025-09-20 20:12:40,186 [trainer.py] => dataset: cifar100_224
2025-09-20 20:12:40,186 [trainer.py] => smart_defaults: True
2025-09-20 20:12:40,186 [trainer.py] => user: authors
2025-09-20 20:12:40,186 [trainer.py] => test: True
2025-09-20 20:12:40,187 [trainer.py] => memory_size: 0
2025-09-20 20:12:40,187 [trainer.py] => memory_per_class: 0
2025-09-20 20:12:40,187 [trainer.py] => fixed_memory: False
2025-09-20 20:12:40,187 [trainer.py] => shuffle: True
2025-09-20 20:12:40,187 [trainer.py] => init_cls: 10
2025-09-20 20:12:40,187 [trainer.py] => increment: 10
2025-09-20 20:12:40,187 [trainer.py] => model_name: sldc
2025-09-20 20:12:40,187 [trainer.py] => vit_type: vit-b-p16
2025-09-20 20:12:40,187 [trainer.py] => weight_decay: 0.0
2025-09-20 20:12:40,187 [trainer.py] => device: [device(type='cuda', index=0)]
2025-09-20 20:12:40,187 [trainer.py] => lora_rank: 4
2025-09-20 20:12:40,187 [trainer.py] => lora_type: sgp_lora
2025-09-20 20:12:40,187 [trainer.py] => weight_temp: 5.0
2025-09-20 20:12:40,187 [trainer.py] => weight_kind: log1p
2025-09-20 20:12:40,187 [trainer.py] => weight_p: 1.0
2025-09-20 20:12:40,187 [trainer.py] => nsp_eps: 0.05
2025-09-20 20:12:40,187 [trainer.py] => nsp_weight: 0.0
2025-09-20 20:12:40,187 [trainer.py] => sce_a: 0.5
2025-09-20 20:12:40,187 [trainer.py] => sce_b: 0.5
2025-09-20 20:12:40,187 [trainer.py] => seed_list: [1993]
2025-09-20 20:12:40,187 [trainer.py] => iterations: 2500
2025-09-20 20:12:40,187 [trainer.py] => warmup_steps: 200
2025-09-20 20:12:40,187 [trainer.py] => ca_epochs: 5
2025-09-20 20:12:40,187 [trainer.py] => optimizer: sgd
2025-09-20 20:12:40,187 [trainer.py] => lrate: 0.002
2025-09-20 20:12:40,187 [trainer.py] => batch_size: 24
2025-09-20 20:12:40,187 [trainer.py] => gamma_norm: 0.1
2025-09-20 20:12:40,187 [trainer.py] => gamma_kd: 0.0
2025-09-20 20:12:40,187 [trainer.py] => kd_type: feat
2025-09-20 20:12:40,187 [trainer.py] => compensate: True
2025-09-20 20:12:40,187 [trainer.py] => eval_only: False
2025-09-20 20:12:40,187 [trainer.py] => auxiliary_data_path: /data1/open_datasets/ImageNet-2012/train
2025-09-20 20:12:40,187 [trainer.py] => aux_dataset: imagenet
2025-09-20 20:12:40,188 [trainer.py] => auxiliary_data_size: 1024
2025-09-20 20:12:40,188 [trainer.py] => l2_protection: True
2025-09-20 20:12:40,188 [trainer.py] => l2_protection_lambda: 0.0001
2025-09-20 20:12:40,188 [trainer.py] => seed: 1993
2025-09-20 20:12:40,188 [trainer.py] => run_id: 0
2025-09-20 20:12:40,188 [trainer.py] => log_path: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993
2025-09-20 20:12:40,188 [data_manager.py] => [DataManager] args_for_idata = {'dataset': 'cifar100_224', 'smart_defaults': True, 'user': 'authors', 'test': True, 'memory_size': 0, 'memory_per_class': 0, 'fixed_memory': False, 'shuffle': True, 'init_cls': 10, 'increment': 10, 'model_name': 'sldc', 'vit_type': 'vit-b-p16', 'weight_decay': 0.0, 'device': [device(type='cuda', index=0)], 'lora_rank': 4, 'lora_type': 'sgp_lora', 'weight_temp': 5.0, 'weight_kind': 'log1p', 'weight_p': 1.0, 'nsp_eps': 0.05, 'nsp_weight': 0.0, 'sce_a': 0.5, 'sce_b': 0.5, 'seed_list': [1993], 'iterations': 2500, 'warmup_steps': 200, 'ca_epochs': 5, 'optimizer': 'sgd', 'lrate': 0.002, 'batch_size': 24, 'gamma_norm': 0.1, 'gamma_kd': 0.0, 'kd_type': 'feat', 'compensate': True, 'eval_only': False, 'auxiliary_data_path': '/data1/open_datasets/ImageNet-2012/train', 'aux_dataset': 'imagenet', 'auxiliary_data_size': 1024, 'l2_protection': True, 'l2_protection_lambda': 0.0001, 'seed': 1993, 'run_id': 0, 'log_path': 'sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993'}
2025-09-20 20:12:42,136 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-09-20 20:12:43,443 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-09-20 20:12:44,045 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-09-20 20:13:01,751 [subspace_lora.py] => Compiled network with torch.compile
2025-09-20 20:13:01,751 [subspace_lora.py] => Optimizer instantiated: lrate=0.002, wd=0.0, optimizer=sgd
2025-09-20 20:13:01,752 [trainer.py] => All params: 86469888
2025-09-20 20:13:01,752 [trainer.py] => Trainable params: 672768
2025-09-20 20:13:01,861 [subspace_lora.py] => System training on classes 0-10 (cifar100_224)
2025-09-23 19:20:38,919 [trainer.py] => dataset: cifar100_224
2025-09-23 19:20:38,919 [trainer.py] => smart_defaults: True
2025-09-23 19:20:38,919 [trainer.py] => user: authors
2025-09-23 19:20:38,919 [trainer.py] => test: True
2025-09-23 19:20:38,919 [trainer.py] => memory_size: 0
2025-09-23 19:20:38,919 [trainer.py] => memory_per_class: 0
2025-09-23 19:20:38,919 [trainer.py] => fixed_memory: False
2025-09-23 19:20:38,919 [trainer.py] => shuffle: True
2025-09-23 19:20:38,919 [trainer.py] => init_cls: 10
2025-09-23 19:20:38,919 [trainer.py] => increment: 10
2025-09-23 19:20:38,919 [trainer.py] => model_name: sldc
2025-09-23 19:20:38,919 [trainer.py] => vit_type: vit-b-p16
2025-09-23 19:20:38,919 [trainer.py] => weight_decay: 0.0
2025-09-23 19:20:38,919 [trainer.py] => device: [device(type='cuda', index=0)]
2025-09-23 19:20:38,919 [trainer.py] => lora_rank: 4
2025-09-23 19:20:38,919 [trainer.py] => lora_type: sgp_lora
2025-09-23 19:20:38,920 [trainer.py] => weight_temp: 5.0
2025-09-23 19:20:38,920 [trainer.py] => weight_kind: log1p
2025-09-23 19:20:38,920 [trainer.py] => weight_p: 1.0
2025-09-23 19:20:38,920 [trainer.py] => nsp_eps: 0.05
2025-09-23 19:20:38,920 [trainer.py] => nsp_weight: 0.0
2025-09-23 19:20:38,920 [trainer.py] => sce_a: 0.5
2025-09-23 19:20:38,920 [trainer.py] => sce_b: 0.5
2025-09-23 19:20:38,920 [trainer.py] => seed_list: [1993]
2025-09-23 19:20:38,920 [trainer.py] => iterations: 2500
2025-09-23 19:20:38,920 [trainer.py] => warmup_steps: 200
2025-09-23 19:20:38,920 [trainer.py] => ca_epochs: 5
2025-09-23 19:20:38,920 [trainer.py] => optimizer: sgd
2025-09-23 19:20:38,920 [trainer.py] => lrate: 0.002
2025-09-23 19:20:38,920 [trainer.py] => batch_size: 24
2025-09-23 19:20:38,920 [trainer.py] => gamma_norm: 0.1
2025-09-23 19:20:38,920 [trainer.py] => gamma_kd: 0.0
2025-09-23 19:20:38,920 [trainer.py] => kd_type: feat
2025-09-23 19:20:38,920 [trainer.py] => compensate: True
2025-09-23 19:20:38,920 [trainer.py] => eval_only: False
2025-09-23 19:20:38,920 [trainer.py] => auxiliary_data_path: /data1/open_datasets/ImageNet-2012/train
2025-09-23 19:20:38,920 [trainer.py] => aux_dataset: imagenet
2025-09-23 19:20:38,920 [trainer.py] => auxiliary_data_size: 1024
2025-09-23 19:20:38,920 [trainer.py] => l2_protection: True
2025-09-23 19:20:38,920 [trainer.py] => l2_protection_lambda: 0.0001
2025-09-23 19:20:38,920 [trainer.py] => seed: 1993
2025-09-23 19:20:38,920 [trainer.py] => run_id: 0
2025-09-23 19:20:38,920 [trainer.py] => log_path: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993
2025-09-23 19:20:38,920 [data_manager.py] => [DataManager] args_for_idata = {'dataset': 'cifar100_224', 'smart_defaults': True, 'user': 'authors', 'test': True, 'memory_size': 0, 'memory_per_class': 0, 'fixed_memory': False, 'shuffle': True, 'init_cls': 10, 'increment': 10, 'model_name': 'sldc', 'vit_type': 'vit-b-p16', 'weight_decay': 0.0, 'device': [device(type='cuda', index=0)], 'lora_rank': 4, 'lora_type': 'sgp_lora', 'weight_temp': 5.0, 'weight_kind': 'log1p', 'weight_p': 1.0, 'nsp_eps': 0.05, 'nsp_weight': 0.0, 'sce_a': 0.5, 'sce_b': 0.5, 'seed_list': [1993], 'iterations': 2500, 'warmup_steps': 200, 'ca_epochs': 5, 'optimizer': 'sgd', 'lrate': 0.002, 'batch_size': 24, 'gamma_norm': 0.1, 'gamma_kd': 0.0, 'kd_type': 'feat', 'compensate': True, 'eval_only': False, 'auxiliary_data_path': '/data1/open_datasets/ImageNet-2012/train', 'aux_dataset': 'imagenet', 'auxiliary_data_size': 1024, 'l2_protection': True, 'l2_protection_lambda': 0.0001, 'seed': 1993, 'run_id': 0, 'log_path': 'sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993'}
2025-09-23 19:20:40,863 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-09-23 19:20:41,996 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-09-23 19:20:42,394 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-09-23 19:20:57,093 [subspace_lora.py] => Compiled network with torch.compile
2025-09-23 19:20:57,094 [subspace_lora.py] => Optimizer instantiated: lrate=0.002, wd=0.0, optimizer=sgd
2025-09-23 19:20:57,094 [trainer.py] => All params: 86469888
2025-09-23 19:20:57,095 [trainer.py] => Trainable params: 672768
2025-09-23 19:20:57,237 [subspace_lora.py] => System training on classes 0-10 (cifar100_224)
2025-09-23 22:20:49,546 [trainer.py] => dataset: cifar100_224
2025-09-23 22:20:49,546 [trainer.py] => smart_defaults: True
2025-09-23 22:20:49,546 [trainer.py] => user: authors
2025-09-23 22:20:49,546 [trainer.py] => test: True
2025-09-23 22:20:49,546 [trainer.py] => memory_size: 0
2025-09-23 22:20:49,546 [trainer.py] => memory_per_class: 0
2025-09-23 22:20:49,546 [trainer.py] => fixed_memory: False
2025-09-23 22:20:49,546 [trainer.py] => shuffle: True
2025-09-23 22:20:49,546 [trainer.py] => init_cls: 10
2025-09-23 22:20:49,547 [trainer.py] => increment: 10
2025-09-23 22:20:49,547 [trainer.py] => model_name: sldc
2025-09-23 22:20:49,547 [trainer.py] => vit_type: vit-b-p16
2025-09-23 22:20:49,547 [trainer.py] => weight_decay: 0.0
2025-09-23 22:20:49,547 [trainer.py] => device: [device(type='cuda', index=0)]
2025-09-23 22:20:49,547 [trainer.py] => lora_rank: 4
2025-09-23 22:20:49,547 [trainer.py] => lora_type: sgp_lora
2025-09-23 22:20:49,547 [trainer.py] => weight_temp: 5.0
2025-09-23 22:20:49,547 [trainer.py] => weight_kind: log1p
2025-09-23 22:20:49,547 [trainer.py] => weight_p: 1.0
2025-09-23 22:20:49,547 [trainer.py] => nsp_eps: 0.05
2025-09-23 22:20:49,547 [trainer.py] => nsp_weight: 0.0
2025-09-23 22:20:49,547 [trainer.py] => sce_a: 0.5
2025-09-23 22:20:49,547 [trainer.py] => sce_b: 0.5
2025-09-23 22:20:49,547 [trainer.py] => seed_list: [1993]
2025-09-23 22:20:49,547 [trainer.py] => iterations: 2500
2025-09-23 22:20:49,547 [trainer.py] => warmup_steps: 200
2025-09-23 22:20:49,547 [trainer.py] => ca_epochs: 5
2025-09-23 22:20:49,547 [trainer.py] => optimizer: sgd
2025-09-23 22:20:49,547 [trainer.py] => lrate: 0.002
2025-09-23 22:20:49,547 [trainer.py] => batch_size: 24
2025-09-23 22:20:49,547 [trainer.py] => gamma_norm: 0.1
2025-09-23 22:20:49,547 [trainer.py] => gamma_kd: 0.0
2025-09-23 22:20:49,547 [trainer.py] => kd_type: feat
2025-09-23 22:20:49,547 [trainer.py] => compensate: True
2025-09-23 22:20:49,547 [trainer.py] => eval_only: False
2025-09-23 22:20:49,547 [trainer.py] => auxiliary_data_path: /data1/open_datasets/ImageNet-2012/train
2025-09-23 22:20:49,547 [trainer.py] => aux_dataset: imagenet
2025-09-23 22:20:49,547 [trainer.py] => auxiliary_data_size: 1024
2025-09-23 22:20:49,547 [trainer.py] => l2_protection: True
2025-09-23 22:20:49,548 [trainer.py] => l2_protection_lambda: 0.0001
2025-09-23 22:20:49,548 [trainer.py] => seed: 1993
2025-09-23 22:20:49,548 [trainer.py] => run_id: 0
2025-09-23 22:20:49,548 [trainer.py] => log_path: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993
2025-09-23 22:20:49,548 [data_manager.py] => [DataManager] args_for_idata = {'dataset': 'cifar100_224', 'smart_defaults': True, 'user': 'authors', 'test': True, 'memory_size': 0, 'memory_per_class': 0, 'fixed_memory': False, 'shuffle': True, 'init_cls': 10, 'increment': 10, 'model_name': 'sldc', 'vit_type': 'vit-b-p16', 'weight_decay': 0.0, 'device': [device(type='cuda', index=0)], 'lora_rank': 4, 'lora_type': 'sgp_lora', 'weight_temp': 5.0, 'weight_kind': 'log1p', 'weight_p': 1.0, 'nsp_eps': 0.05, 'nsp_weight': 0.0, 'sce_a': 0.5, 'sce_b': 0.5, 'seed_list': [1993], 'iterations': 2500, 'warmup_steps': 200, 'ca_epochs': 5, 'optimizer': 'sgd', 'lrate': 0.002, 'batch_size': 24, 'gamma_norm': 0.1, 'gamma_kd': 0.0, 'kd_type': 'feat', 'compensate': True, 'eval_only': False, 'auxiliary_data_path': '/data1/open_datasets/ImageNet-2012/train', 'aux_dataset': 'imagenet', 'auxiliary_data_size': 1024, 'l2_protection': True, 'l2_protection_lambda': 0.0001, 'seed': 1993, 'run_id': 0, 'log_path': 'sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993'}
2025-09-23 22:20:51,497 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-09-23 22:20:52,637 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-09-23 22:20:54,276 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-09-23 22:21:07,751 [subspace_lora.py] => Compiled network with torch.compile
2025-09-23 22:21:07,751 [subspace_lora.py] => Optimizer instantiated: lrate=0.002, wd=0.0, optimizer=sgd
2025-09-23 22:21:07,752 [trainer.py] => All params: 86469888
2025-09-23 22:21:07,753 [trainer.py] => Trainable params: 672768
2025-09-23 22:21:07,942 [subspace_lora.py] => System training on classes 0-10 (cifar100_224)
2025-09-23 22:22:22,404 [trainer.py] => dataset: cifar100_224
2025-09-23 22:22:22,404 [trainer.py] => smart_defaults: True
2025-09-23 22:22:22,404 [trainer.py] => user: authors
2025-09-23 22:22:22,405 [trainer.py] => test: True
2025-09-23 22:22:22,405 [trainer.py] => memory_size: 0
2025-09-23 22:22:22,405 [trainer.py] => memory_per_class: 0
2025-09-23 22:22:22,405 [trainer.py] => fixed_memory: False
2025-09-23 22:22:22,405 [trainer.py] => shuffle: True
2025-09-23 22:22:22,405 [trainer.py] => init_cls: 10
2025-09-23 22:22:22,405 [trainer.py] => increment: 10
2025-09-23 22:22:22,405 [trainer.py] => model_name: sldc
2025-09-23 22:22:22,405 [trainer.py] => vit_type: vit-b-p16
2025-09-23 22:22:22,405 [trainer.py] => weight_decay: 0.0
2025-09-23 22:22:22,405 [trainer.py] => device: [device(type='cuda', index=0)]
2025-09-23 22:22:22,405 [trainer.py] => lora_rank: 4
2025-09-23 22:22:22,405 [trainer.py] => lora_type: sgp_lora
2025-09-23 22:22:22,405 [trainer.py] => weight_temp: 5.0
2025-09-23 22:22:22,405 [trainer.py] => weight_kind: log1p
2025-09-23 22:22:22,405 [trainer.py] => weight_p: 1.0
2025-09-23 22:22:22,405 [trainer.py] => nsp_eps: 0.05
2025-09-23 22:22:22,405 [trainer.py] => nsp_weight: 0.0
2025-09-23 22:22:22,405 [trainer.py] => sce_a: 0.5
2025-09-23 22:22:22,405 [trainer.py] => sce_b: 0.5
2025-09-23 22:22:22,405 [trainer.py] => seed_list: [1993]
2025-09-23 22:22:22,405 [trainer.py] => iterations: 2500
2025-09-23 22:22:22,406 [trainer.py] => warmup_steps: 200
2025-09-23 22:22:22,406 [trainer.py] => ca_epochs: 5
2025-09-23 22:22:22,406 [trainer.py] => optimizer: sgd
2025-09-23 22:22:22,406 [trainer.py] => lrate: 0.002
2025-09-23 22:22:22,406 [trainer.py] => batch_size: 24
2025-09-23 22:22:22,406 [trainer.py] => gamma_norm: 0.1
2025-09-23 22:22:22,406 [trainer.py] => gamma_kd: 0.0
2025-09-23 22:22:22,406 [trainer.py] => kd_type: feat
2025-09-23 22:22:22,406 [trainer.py] => compensate: True
2025-09-23 22:22:22,406 [trainer.py] => eval_only: False
2025-09-23 22:22:22,406 [trainer.py] => auxiliary_data_path: /data1/open_datasets/ImageNet-2012/train
2025-09-23 22:22:22,406 [trainer.py] => aux_dataset: imagenet
2025-09-23 22:22:22,406 [trainer.py] => auxiliary_data_size: 1024
2025-09-23 22:22:22,406 [trainer.py] => l2_protection: True
2025-09-23 22:22:22,406 [trainer.py] => l2_protection_lambda: 0.0001
2025-09-23 22:22:22,406 [trainer.py] => seed: 1993
2025-09-23 22:22:22,406 [trainer.py] => run_id: 0
2025-09-23 22:22:22,406 [trainer.py] => log_path: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993
2025-09-23 22:22:22,406 [data_manager.py] => [DataManager] args_for_idata = {'dataset': 'cifar100_224', 'smart_defaults': True, 'user': 'authors', 'test': True, 'memory_size': 0, 'memory_per_class': 0, 'fixed_memory': False, 'shuffle': True, 'init_cls': 10, 'increment': 10, 'model_name': 'sldc', 'vit_type': 'vit-b-p16', 'weight_decay': 0.0, 'device': [device(type='cuda', index=0)], 'lora_rank': 4, 'lora_type': 'sgp_lora', 'weight_temp': 5.0, 'weight_kind': 'log1p', 'weight_p': 1.0, 'nsp_eps': 0.05, 'nsp_weight': 0.0, 'sce_a': 0.5, 'sce_b': 0.5, 'seed_list': [1993], 'iterations': 2500, 'warmup_steps': 200, 'ca_epochs': 5, 'optimizer': 'sgd', 'lrate': 0.002, 'batch_size': 24, 'gamma_norm': 0.1, 'gamma_kd': 0.0, 'kd_type': 'feat', 'compensate': True, 'eval_only': False, 'auxiliary_data_path': '/data1/open_datasets/ImageNet-2012/train', 'aux_dataset': 'imagenet', 'auxiliary_data_size': 1024, 'l2_protection': True, 'l2_protection_lambda': 0.0001, 'seed': 1993, 'run_id': 0, 'log_path': 'sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993'}
2025-09-23 22:22:24,349 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-09-23 22:22:25,602 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-09-23 22:22:26,419 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-09-23 22:22:43,215 [subspace_lora.py] => Compiled network with torch.compile
2025-09-23 22:22:43,215 [subspace_lora.py] => Optimizer instantiated: lrate=0.002, wd=0.0, optimizer=sgd
2025-09-23 22:22:43,216 [trainer.py] => All params: 86469888
2025-09-23 22:22:43,216 [trainer.py] => Trainable params: 672768
2025-09-23 22:22:43,375 [subspace_lora.py] => System training on classes 0-10 (cifar100_224)
2025-09-23 22:54:45,458 [trainer.py] => dataset: cifar100_224
2025-09-23 22:54:45,458 [trainer.py] => smart_defaults: True
2025-09-23 22:54:45,458 [trainer.py] => user: authors
2025-09-23 22:54:45,458 [trainer.py] => test: True
2025-09-23 22:54:45,458 [trainer.py] => memory_size: 0
2025-09-23 22:54:45,458 [trainer.py] => memory_per_class: 0
2025-09-23 22:54:45,458 [trainer.py] => fixed_memory: False
2025-09-23 22:54:45,458 [trainer.py] => shuffle: True
2025-09-23 22:54:45,458 [trainer.py] => init_cls: 10
2025-09-23 22:54:45,458 [trainer.py] => increment: 10
2025-09-23 22:54:45,458 [trainer.py] => model_name: sldc
2025-09-23 22:54:45,458 [trainer.py] => vit_type: vit-b-p16
2025-09-23 22:54:45,458 [trainer.py] => weight_decay: 0.0
2025-09-23 22:54:45,458 [trainer.py] => device: [device(type='cuda', index=0)]
2025-09-23 22:54:45,458 [trainer.py] => lora_rank: 4
2025-09-23 22:54:45,458 [trainer.py] => lora_type: sgp_lora
2025-09-23 22:54:45,458 [trainer.py] => weight_temp: 5.0
2025-09-23 22:54:45,458 [trainer.py] => weight_kind: log1p
2025-09-23 22:54:45,458 [trainer.py] => weight_p: 1.0
2025-09-23 22:54:45,458 [trainer.py] => nsp_eps: 0.05
2025-09-23 22:54:45,458 [trainer.py] => nsp_weight: 0.0
2025-09-23 22:54:45,458 [trainer.py] => sce_a: 0.5
2025-09-23 22:54:45,459 [trainer.py] => sce_b: 0.5
2025-09-23 22:54:45,459 [trainer.py] => seed_list: [1993]
2025-09-23 22:54:45,459 [trainer.py] => iterations: 2500
2025-09-23 22:54:45,459 [trainer.py] => warmup_steps: 200
2025-09-23 22:54:45,459 [trainer.py] => ca_epochs: 5
2025-09-23 22:54:45,459 [trainer.py] => optimizer: sgd
2025-09-23 22:54:45,459 [trainer.py] => lrate: 0.002
2025-09-23 22:54:45,459 [trainer.py] => batch_size: 24
2025-09-23 22:54:45,459 [trainer.py] => gamma_norm: 0.1
2025-09-23 22:54:45,459 [trainer.py] => gamma_kd: 0.0
2025-09-23 22:54:45,459 [trainer.py] => kd_type: feat
2025-09-23 22:54:45,459 [trainer.py] => compensate: True
2025-09-23 22:54:45,459 [trainer.py] => eval_only: False
2025-09-23 22:54:45,459 [trainer.py] => auxiliary_data_path: /data1/open_datasets/ImageNet-2012/train
2025-09-23 22:54:45,459 [trainer.py] => aux_dataset: imagenet
2025-09-23 22:54:45,459 [trainer.py] => auxiliary_data_size: 1024
2025-09-23 22:54:45,459 [trainer.py] => l2_protection: True
2025-09-23 22:54:45,459 [trainer.py] => l2_protection_lambda: 0.0001
2025-09-23 22:54:45,459 [trainer.py] => seed: 1993
2025-09-23 22:54:45,459 [trainer.py] => run_id: 0
2025-09-23 22:54:45,459 [trainer.py] => log_path: sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993
2025-09-23 22:54:45,459 [data_manager.py] => [DataManager] args_for_idata = {'dataset': 'cifar100_224', 'smart_defaults': True, 'user': 'authors', 'test': True, 'memory_size': 0, 'memory_per_class': 0, 'fixed_memory': False, 'shuffle': True, 'init_cls': 10, 'increment': 10, 'model_name': 'sldc', 'vit_type': 'vit-b-p16', 'weight_decay': 0.0, 'device': [device(type='cuda', index=0)], 'lora_rank': 4, 'lora_type': 'sgp_lora', 'weight_temp': 5.0, 'weight_kind': 'log1p', 'weight_p': 1.0, 'nsp_eps': 0.05, 'nsp_weight': 0.0, 'sce_a': 0.5, 'sce_b': 0.5, 'seed_list': [1993], 'iterations': 2500, 'warmup_steps': 200, 'ca_epochs': 5, 'optimizer': 'sgd', 'lrate': 0.002, 'batch_size': 24, 'gamma_norm': 0.1, 'gamma_kd': 0.0, 'kd_type': 'feat', 'compensate': True, 'eval_only': False, 'auxiliary_data_path': '/data1/open_datasets/ImageNet-2012/train', 'aux_dataset': 'imagenet', 'auxiliary_data_size': 1024, 'l2_protection': True, 'l2_protection_lambda': 0.0001, 'seed': 1993, 'run_id': 0, 'log_path': 'sldc_logs_authors/cifar100_224_vit-b-p16/init-10_inc-10_rank-4_lt-sgp_lora_T-5_comp-1_wk-log1p_wp-1_kd-feat_gkd-0_gn-0p1_optim-sgd_lr-0p002_bz-24_iter-2500_seed-1993'}
2025-09-23 22:54:47,231 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-09-23 22:54:48,396 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-09-23 22:54:49,034 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-09-23 22:55:03,586 [subspace_lora.py] => Compiled network with torch.compile
2025-09-23 22:55:03,587 [subspace_lora.py] => Optimizer instantiated: lrate=0.002, wd=0.0, optimizer=sgd
2025-09-23 22:55:03,587 [trainer.py] => All params: 86469888
2025-09-23 22:55:03,588 [trainer.py] => Trainable params: 672768
2025-09-23 22:55:03,736 [subspace_lora.py] => System training on classes 0-10 (cifar100_224)
